import os
import re # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å re –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏
import uuid
import time
import logging
from typing import List, Tuple, Dict
from docx import Document # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ python-docx
from supabase import create_client, Client
from dotenv import load_dotenv

# üí° –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–≥–æ–≤ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
import config
import db as db_utils
from embeddings import generate_search_tags

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DOCX_FILE = "catalog.docx"
SUPABASE_BUCKET = os.getenv("SUPABASE_BUCKET", "products")

def guess_ext_and_mime(content_type: str, partname: str) -> Tuple[str, str]:
    ext = ""
    mime = content_type or "application/octet-stream"
    if partname:
        _, ext_candidate = os.path.splitext(str(partname))
        if ext_candidate:
            ext = ext_candidate.lower().lstrip(".")
    if not ext:
        mime_map = {"image/jpeg": "jpg", "image/png": "png", "image/gif": "gif", "image/webp": "webp"}
        ext = mime_map.get(mime, "jpg")
    return ext, mime

def create_and_embed_chunks(product_id: int, product_name: str, description: str, tags: str):
    """
    –°–æ–∑–¥–∞–µ—Ç –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —á–∞–Ω–∫–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞: –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –∫–∞–∂–¥—ã–π —Ç–µ–≥ –æ—Ç–¥–µ–ª—å–Ω–æ.
    """
    chunks_to_insert = []

    # 1. –ß–∞–Ω–∫ –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è
    chunks_to_insert.append({"product_id": product_id, "content": product_name})

    # 2. –ß–∞–Ω–∫ –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è
    if description:
        chunks_to_insert.append({"product_id": product_id, "content": description})

    # 3. –û—Ç–¥–µ–ª—å–Ω—ã–µ —á–∞–Ω–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–≥–∞
    if tags:
        tag_list = [tag.strip() for tag in tags.split(',') if tag.strip()]
        for tag in tag_list:
            chunks_to_insert.append({"product_id": product_id, "content": tag})

    # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –≥–æ—Ç–æ–≤–∏–º –∫ –∑–∞–≥—Ä—É–∑–∫–µ
    final_chunks = []
    for chunk in chunks_to_insert:
        embedding = db_utils.embed_text(chunk['content'])
        if embedding:
            chunk['embedding'] = embedding
            final_chunks.append(chunk)
    
    # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —á–∞–Ω–∫–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
    if final_chunks:
        db_utils.supabase.table("catalog_chunks").insert(final_chunks).execute()
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(final_chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ ID {product_id}.")

def process_and_embed_catalog(docx_path: str):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–∞—Ä—Å–∏—Ç —Ç–∞–±–ª–∏—Ü—É –∏–∑ DOCX, –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–≤–∞—Ä—ã, —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ Supabase.
    """
    if not os.path.exists(docx_path):
        logger.error(f"–§–∞–π–ª –∫–∞—Ç–∞–ª–æ–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {docx_path}")
        return
        
    logger.info(f"üìÑ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞: {docx_path}")
    
    # 1. –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    logger.info("üóëÔ∏è –û—á–∏—â–∞—é —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (chunks)...")
    # üí° –ò–ó–ú–ï–ù–ï–ù–ò–ï: –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å–∏ –±–∞—Ç—á–∞–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ç–∞–π–º–∞—É—Ç–∞
    batch_size = 1000  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (–º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å)
    while True:
        # 1. –ü–æ–ª—É—á–∞–µ–º ID —Å–ª–µ–¥—É—é—â–µ–≥–æ –±–∞—Ç—á–∞
        res = db_utils.supabase.table("catalog_chunks").select("id").limit(batch_size).execute()
        
        # 2. –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –∑–Ω–∞—á–∏—Ç —Ç–∞–±–ª–∏—Ü–∞ –ø—É—Å—Ç–∞, –≤—ã—Ö–æ–¥–∏–º
        if not res.data:
            logger.info("‚úÖ –í—Å–µ —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —É–¥–∞–ª–µ–Ω—ã.")
            break
            
        # 3. –°–æ–±–∏—Ä–∞–µ–º ID –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∏ —É–¥–∞–ª—è–µ–º –±–∞—Ç—á
        ids_to_delete = [item["id"] for item in res.data]
        db_utils.supabase.table("catalog_chunks").delete().in_("id", ids_to_delete).execute()
        logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ {len(ids_to_delete)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (chunks)...")
        
        # 4. –ï—Å–ª–∏ —É–¥–∞–ª–∏–ª–∏ –º–µ–Ω—å—à–µ, —á–µ–º —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —ç—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–∞—Ç—á.
        if len(ids_to_delete) < batch_size:
            logger.info("‚úÖ –í—Å–µ —Å—Ç–∞—Ä—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —É–¥–∞–ª–µ–Ω—ã.")
            break
    
    # 2. –û—Ç–∫—Ä—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏ –∏—Ç–µ—Ä–∏—Ä—É–µ–º –ø–æ —Ç–∞–±–ª–∏—Ü–∞–º
    doc = Document(docx_path)
    total_products_processed = 0

    for table_idx, table in enumerate(doc.tables):
        logger.info(f"--- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–∞–±–ª–∏—Ü—ã #{table_idx+1} ---")
        
        for row_idx, row in enumerate(table.rows):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
            if row_idx == 0:
                continue

            try:
                # --- 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —è—á–µ–µ–∫ ---
                # –Ø—á–µ–π–∫–∞ 0: –§–æ—Ç–æ
                # –Ø—á–µ–π–∫–∞ 1: –ù–∞–∑–≤–∞–Ω–∏–µ
                # –Ø—á–µ–π–∫–∞ 2: –û–ø–∏—Å–∞–Ω–∏–µ
                # –Ø—á–µ–π–∫–∞ 3: –¶–µ–Ω–∞ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ü–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∑–¥–µ—Å—å)
                
                name_cell = row.cells[1]
                description_cell = row.cells[2]
                price_cell = row.cells[3] # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ü–µ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ 4-–π —è—á–µ–π–∫–µ
                
                product_name = name_cell.text.strip()
                description = description_cell.text.strip()
                raw_price = price_cell.text.strip()
                product_price = None
                try:
                    # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—á–∏—Å–ª–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫—Ä–æ–º–µ —Ç–æ—á–∫–∏/–∑–∞–ø—è—Ç–æ–π, –∏ –ø—ã—Ç–∞–µ–º—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ
                    cleaned_price = re.sub(r'[^\d.,]+', '', raw_price).replace(',', '.')
                    product_price = float(cleaned_price)
                except ValueError:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Ü–µ–Ω—É '{raw_price}' –¥–ª—è —Ç–æ–≤–∞—Ä–∞ '{product_name}'.")

                if not product_name or not description:
                    logger.warning(f"–ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç—Ä–æ–∫—É #{row_idx+1}: –Ω–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è.")
                    continue

                logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –∑–∞–ø–∏—Å—å: '{product_name}'")

                # --- 4. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
                image_url = None
                image_cell = row.cells[0]
                blips = image_cell._element.xpath(".//a:blip")
                if blips:
                    rid = blips[0].get("{http://schemas.openxmlformats.org/officeDocument/2006/relationships}embed")
                    if rid:
                        image_part = doc.part.related_parts[rid]
                        ext, mime = guess_ext_and_mime(image_part.content_type, str(image_part.partname))
                        
                        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤ Supabase Storage
                        try:
                            path = f"{uuid.uuid4()}_product.{ext}"
                            db_utils.supabase.storage.from_(SUPABASE_BUCKET).upload(
                                path, image_part.blob, file_options={"content-type": mime, "upsert": "true"}
                            )
                            image_url = f"{config.SUPABASE_URL}/storage/v1/object/public/{SUPABASE_BUCKET}/{path}"
                            logger.info(f"üñºÔ∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è '{product_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {image_url}")
                        except Exception as img_e:
                            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è '{product_name}': {img_e}")
                            image_url = None # –Ø–≤–Ω–æ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º URL –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

                # --- 5. –£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–≥–æ–≤ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ ---
                tags = None
                # –ò—â–µ–º —Ç–æ–≤–∞—Ä –≤ –±–∞–∑–µ –ø–æ –∏–º–µ–Ω–∏, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å —Ç–µ–≥–∏
                existing_product_res = db_utils.supabase.table("products").select("description, search_tags").eq("name", product_name).maybe_single().execute()
                # üí° –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É, —á—Ç–æ –æ—Ç–≤–µ—Ç –æ—Ç API –Ω–µ –ø—É—Å—Ç–æ–π (None)
                # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –æ—à–∏–±–∫–∏ 'NoneType' object has no attribute 'data' –ø—Ä–∏ HTTP-–æ—à–∏–±–∫–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 406 Not Acceptable)
                existing_product = existing_product_res.data if existing_product_res else None
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–≥–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä–∞ –Ω–µ—Ç, —É –Ω–µ–≥–æ –Ω–µ—Ç —Ç–µ–≥–æ–≤, –∏–ª–∏ –µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å.
                if not existing_product or not existing_product.get("search_tags") or existing_product.get("description") != description:

                    logger.info(f"–¢—Ä–µ–±—É–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–≥–æ–≤ –¥–ª—è '{product_name}'. –ó–∞–ø—É—Å–∫–∞—é LLM...")
                    tags = generate_search_tags(description)
                    if tags:
                        logger.info(f"üè∑Ô∏è  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ç–µ–≥–∏: {tags}")
                    else:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–≥–∏ –¥–ª—è '{product_name}'.")
                else:
                    logger.info(f"–¢–µ–≥–∏ –¥–ª—è '{product_name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã. –ü—Ä–æ–ø—É—Å–∫–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.")
                    tags = existing_product["search_tags"] # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–µ–≥–∏

                product_data = {
                    "name": product_name,
                    "description": description,
                    "price": product_price, # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—É—é —Ü–µ–Ω—É
                    "images": [image_url] if image_url else None,
                    "search_tags": tags,
                }
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º upsert –¥–ª—è –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è/–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                response = db_utils.supabase.table("products").upsert(product_data, on_conflict="name").execute()
                product_id = response.data[0]['id']
                logger.info(f"‚úÖ –¢–æ–≤–∞—Ä '{product_name}' (ID: {product_id}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")

                # --- 6. üí° –ù–û–í–´–ô –®–ê–ì: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ ---
                # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–∏, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–≥–∏ (—ç—Ç–æ –Ω–∞—à –≥–ª–∞–≤–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç)
                if tags:
                    create_and_embed_chunks(product_id, product_name, description, tags)
                
                total_products_processed += 1

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ #{row_idx+1}: {e}", exc_info=True)
            finally:
                time.sleep(0.1) # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API

    logger.info(f"üéâ –ì–æ—Ç–æ–≤–æ! –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {total_products_processed} —Ç–æ–≤–∞—Ä–æ–≤.")

if __name__ == "__main__":
    process_and_embed_catalog(DOCX_FILE)
