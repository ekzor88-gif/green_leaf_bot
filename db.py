from supabase import create_client
from openai import OpenAI
import config
import json 
import logging
import asyncio 
import pymorphy3 # üí° –ù–û–í–ê–Ø –ë–ò–ë–õ–ò–û–¢–ï–ö–ê

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

# üí° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤
supabase = create_client(config.SUPABASE_URL, config.SUPABASE_KEY)
openai_client = OpenAI(api_key=config.OPENAI_API_KEY)
morph = pymorphy3.MorphAnalyzer() # üí° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞


# ==============================================================================
# 1. –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ë–ê–ó–û–ô –î–ê–ù–ù–´–• (–° –ö–û–†–†–ï–ö–¶–ò–ï–ô ID –ò –ö–û–ù–¢–ï–ö–°–¢–ê)
# ==============================================================================

def upsert_user(user_id: int, first_name: str, last_name: str, username: str):
    """
    –û–±–Ω–æ–≤–ª—è–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
    üí° –ö–æ—Ä—Ä–µ–∫—Ü–∏—è: –ó–¥–µ—Å—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'user_id', —á—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
    """
    return supabase.table("users").upsert({
        "user_id": user_id,
        "first_name": first_name,
        "last_name": last_name,
        "username": username,
    }).execute()


def save_message(user_id: int, role: str, content: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞. –ó–¥–µ—Å—å user_id –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω."""
    return supabase.table("messages").insert({
        "user_id": user_id, "role": role, "content": content
    }).execute()


def get_recent_messages(user_id: int, limit: int = 10):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ó–¥–µ—Å—å user_id –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω."""
    res = (supabase.table("messages")
           .select("*")
           .eq("user_id", user_id)
           .order("id", desc=True)
           .limit(limit)
           .execute())
    return list(reversed(res.data or []))


def save_last_products(user_id: int, products: list):
    """
    –°–û–•–†–ê–ù–Ø–ï–¢ —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤ Supabase.
    üí° –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'user_id'.
    """
    try:
        response = supabase.table('users').update({
            'last_search_results': products 
        }).eq('user_id', user_id).execute() # <--- –ò–°–ü–†–ê–í–õ–ï–ù–û: .eq('user_id', user_id)
        return response
    except Exception as e:
        logger.error(f"[DB] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è {user_id}: {e}")
        return None


def get_last_products(user_id: int) -> list:
    """
    –ò–ó–í–õ–ï–ö–ê–ï–¢ —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –∏–∑ Supabase.
    üí° –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'user_id'.
    """
    try:
        response = (supabase.table('users')
                    .select('last_search_results')
                    .eq('user_id', user_id) # <--- –ò–°–ü–†–ê–í–õ–ï–ù–û: .eq('user_id', user_id)
                    .single()
                    .execute())

        data = response.data
        if data and data.get('last_search_results'):
            return data['last_search_results']
        
        return []
    except Exception as e:
        logger.warning(f"[DB] –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {user_id}: {e}")
        return []

# üöÄ –ù–û–í–ê–Ø/–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
def clear_last_products(user_id: int) -> None:
    """
    –û—á–∏—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (–∫–æ–Ω—Ç–µ–∫—Å—Ç RAG) –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    üí° –ö–†–ò–¢–ò–ß–ï–°–ö–ò –ò–°–ü–†–ê–í–õ–ï–ù–û: –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 'user_id' –∏ 'last_search_results'.
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ 'last_search_results'
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º 'user_id' –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏ 42703 ('column users.id does not exist')
        supabase.table("users").update({"last_search_results": None}).eq("user_id", user_id).execute() # <--- –ò–°–ü–†–ê–í–õ–ï–ù–û
        logger.info("–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –æ—á–∏—â–µ–Ω –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è %d", user_id)
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –¥–ª—è %d: %s", user_id, e)
        
# ==============================================================================
# 2. –§–£–ù–ö–¶–ò–ò LLM –∏ –£–°–ö–û–†–ï–ù–ù–´–ô –ü–û–ò–°–ö (–û–°–¢–ê–í–õ–ï–ù–´ –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô)
# ==============================================================================
def get_product_text_for_embedding(product_data: dict) -> str:
    """
    üí° –ò–°–ü–†–ê–í–õ–ï–ù–û: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ç–æ—á–Ω–æ–π –∫–æ–ø–∏–µ–π
    –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ embeddings.py –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤.
    """
    name = product_data.get('name', '')
    desc = product_data.get('description', '')
    tags = product_data.get('search_tags', '')

    combined_text = (f"–¢–æ–≤–∞—Ä: {name}\n–¢–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞: {tags}\n–û–ø–∏—Å–∞–Ω–∏–µ: {desc}")
    
    # üí° –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    return combined_text.lower()



def embed_text(text: str):
    """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenAI."""
    normalized_text = text.lower()  
    try:
        response = openai_client.embeddings.create(
            input = normalized_text,
            model="text-embedding-3-small"
        )
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"[EMBED] –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
        return None


def search_product_chunks(query: str, top_k: int = 10):
    """
    –ò—â–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –§–†–ê–ì–ú–ï–ù–¢–´ (chunks) –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç `product_id` –∏ `content`.
    """
    normalized_query = query.lower()
    query_vector = embed_text(normalized_query)
    if not query_vector:
        return []

    response = supabase.rpc(
        "match_chunks",
        {
            "query_embedding": query_vector, 
            "match_count": top_k
        }
    ).execute()

    if not response.data:
        return []

    return response.data

def get_products_by_ids(product_ids: list) -> list:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–≤–∞—Ä–∞—Ö –ø–æ —Å–ø–∏—Å–∫—É –∏—Ö ID."""
    if not product_ids:
        return []
    
    response = supabase.rpc(
        "get_products_by_ids", # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —Ç–∞–∫–∞—è RPC —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞
        {"p_ids": product_ids}
    ).execute()
    
    return response.data or []

# üöÄ –ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
def _lemmatize_and_clean_query(query: str) -> list[str]:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç —Å–ª–æ–≤–∞ –≤ –∑–∞–ø—Ä–æ—Å–µ –∫ –Ω–∞—á–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–µ (–ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ—Ç) –∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–∞.
    "—à–∞–º–ø—É–Ω—å —Å –∏–º–±–∏—Ä–µ–º" -> ["—à–∞–º–ø—É–Ω—å", "–∏–º–±–∏—Ä—å"]
    """
    stopwords = {
        "—Å", "–≤", "–Ω–∞", "–∑–∞", "–∏–∑", "–¥–ª—è", "–æ—Ç", "–ø–æ", "—É", "–æ", "–±–µ–∑", "–∏", "–∞", "–Ω–æ",
        "–±—ã—Ç—å", "–≤–µ—Å—å", "—ç—Ç–æ—Ç", "–∫–æ—Ç–æ—Ä—ã–π", "–º–æ–π", "–Ω–∞—à", "–≤–∞—à"
    }
    words = query.lower().replace(',', ' ').replace('.', ' ').split()
    lemmatized_words = []
    for word in words:
        if word not in stopwords:
            lemmatized_words.append(morph.parse(word)[0].normal_form)
    return lemmatized_words

# ‚öôÔ∏è –û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è ‚Äî –û–¥–∏–Ω–∞—Ä–Ω—ã–π –ø–æ–∏—Å–∫ (–ë—ã—Å—Ç—Ä–æ –∏ –¢–æ—á–Ω–æ)
def search_products(user_query: str):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ì–ò–ë–†–ò–î–ù–û–ì–û –ø–æ–∏—Å–∫–∞. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º
    –∏ –ø–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏ —Ç–µ–≥–∞—Ö.
    """
    # --- –®–∞–≥ 0: –û—á–∏—Å—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∫–ª—é—á–µ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ ---
    cleaned_query_words = _lemmatize_and_clean_query(user_query)

    # --- –®–∞–≥ 1: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º (–∫–∞–∫ –∏ —Ä–∞–Ω—å—à–µ) ---
    chunks = search_product_chunks(user_query)
    
    # --- –®–∞–≥ 2: –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º ---
    keyword_products_response = supabase.rpc(
        "keyword_search_products",
        {"search_terms": cleaned_query_words} # <-- –ò–°–ü–û–õ–¨–ó–£–ï–ú –û–ß–ò–©–ï–ù–ù–´–ô –ó–ê–ü–†–û–°
    ).execute()
    keyword_products = keyword_products_response.data or []

    # --- –®–∞–≥ 3: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
    # –°–æ–±–∏—Ä–∞–µ–º ID –∏–∑ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
    semantic_product_ids = {chunk['product_id'] for chunk in chunks}
    # –°–æ–±–∏—Ä–∞–µ–º ID –∏–∑ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    keyword_product_ids = {p['id'] for p in keyword_products}
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ ID
    all_unique_ids = sorted(list(semantic_product_ids.union(keyword_product_ids)))

    if not all_unique_ids:
        return [], [] # –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ

    # --- –®–∞–≥ 4: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–æ–≤–∞—Ä–∞—Ö ---
    final_products = get_products_by_ids(all_unique_ids)

    return final_products, chunks