# embeddings.py

# ...existing code...
import logging
import time
from typing import List, Optional

from openai import OpenAI
import config
from supabase import create_client

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ... (–ø—Ä–æ–≤–µ—Ä–∫–∏ config –æ—Å—Ç–∞—é—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º–∏)

client = OpenAI(api_key=config.OPENAI_API_KEY)
supabase = create_client(config.SUPABASE_URL, config.SUPABASE_KEY)

EMBED_MODEL = "text-embedding-3-small" # 1536 dims

# =================================================================
# üí° –î–û–ë–ê–í–õ–ï–ù–ê: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞ (–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ backfill)
# =================================================================
def get_product_text_for_embedding(product_data: dict) -> str:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –ø–æ–ª—è name, description, search_tags –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
    name = product_data.get('name', '')
    desc = product_data.get('description', '')
    tags = product_data.get('search_tags', '')

    combined_text = (
        f"–¢–æ–≤–∞—Ä: {name}\n"
        f"–¢–µ–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞: {tags}\n"
        f"–û–ø–∏—Å–∞–Ω–∏–µ: {desc}"
    )
    # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    return combined_text.lower()


def generate_search_tags(description: str) -> str:
    """
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–æ—Ç–Ω—ã—Ö, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ —Ç–µ—Ä–º–∏–Ω–æ–≤.
    """
    if not client or not description or len(description) < 20:
        return ""

    prompt = (
        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º Greenleaf. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ—á—å –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∞ "
        "–Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å "
        "–¥–ª—è –ø–æ–∏—Å–∫–∞ —ç—Ç–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –∏–∑ 5-10 –ø–ª–æ—Ç–Ω—ã—Ö, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–≥–æ–≤, "
        "—Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø—è—Ç—ã–º–∏. –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Å–ª–æ–≤ —Ç–∏–ø–∞ '–ø—Ä–æ–¥—É–∫—Ç', '—Å—Ä–µ–¥—Å—Ç–≤–æ'. "
        "–ü—Ä–∏–º–µ—Ä—ã: '—à–∞–º–ø—É–Ω—å –¥–ª—è –≤–æ–ª–æ—Å', '—É–≤–ª–∞–∂–Ω—è—é—â–∏–π –∫—Ä–µ–º –¥–ª—è –ª–∏—Ü–∞', '–≤–∏—Ç–∞–º–∏–Ω—ã –¥–ª—è –∏–º–º—É–Ω–∏—Ç–µ—Ç–∞'."
    )

    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": prompt},
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º LLM –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å, –Ω–æ –Ω–∞ –≤—ã—Ö–æ–¥–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                {"role": "user", "content": description}
            ],
            temperature=0.0
        )
        tags = response.choices[0].message.content.strip()
        return tags.lower() # üí° –ò–ó–ú–ï–ù–ï–ù–ò–ï: –¢–µ–≥–∏ –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    except Exception as e:
        logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–≥–æ–≤: {e}")
        return ""

def _extract_embedding(resp) -> Optional[List[float]]:
    # ... (—Ñ—É–Ω–∫—Ü–∏—è _extract_embedding –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–µ–π)
    try:
        if hasattr(resp, "data") and resp.data:
            emb = resp.data[0].embedding
        else:
            emb = resp.get("data", [None])[0].get("embedding")
    except Exception:
        emb = None
    if emb is None:
        return None
    return list(emb)

def embed_text(text: str) -> Optional[List[float]]:
    if not text:
        return None
    
    # üí° –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥—è—â–∏–π —Ç–µ–∫—Å—Ç –ü–ï–†–ï–î –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
    normalized_text = text.lower()
    
    try:
        resp = client.embeddings.create(model=EMBED_MODEL, input=normalized_text)
        emb = _extract_embedding(resp)
        if not emb:
            logger.warning("–ü—É—Å—Ç–æ–π embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞: %r", normalized_text[:200])
        return emb
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: %s", e)
        return None

# üí° –ò–ó–ú–ï–ù–ï–ù–ò–ï: –î–æ–±–∞–≤–ª–µ–Ω –∞—Ä–≥—É–º–µ–Ω—Ç force_regenerate
def backfill_product_embeddings(batch_size: int = 500, pause_between: float = 0.1, force_regenerate: bool = False):
    
    # ====================================================
    # 1. –¢–ê–ì–ì–ò–†–û–í–ê–ù–ò–ï: –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ search_tags
    # –¢–µ–≥–∏ —Ç–µ–ø–µ—Ä—å –≤—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ.
    # ====================================================
    # ... (–ö–æ–¥ –®–∞–≥–∞ 1 –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º, –∫—Ä–æ–º–µ —Ç–æ–≥–æ, —á—Ç–æ generate_search_tags –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç lower())
    logger.info("--- –®–ê–ì 1: –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–ì–û–í (search_tags) ---")
    
    tag_res = (
        supabase.table("products")
        .select("id,name,description")
        .not_.is_("description", None)
        .is_("search_tags", None)
        .limit(batch_size)
        .execute()
    )
    items_to_tag = tag_res.data
    logger.info("–ù–∞–π–¥–µ–Ω–æ %d –ø—Ä–æ–¥—É–∫—Ç–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö —Ç–µ–≥–∏—Ä–æ–≤–∞–Ω–∏—è", len(items_to_tag))
    
    # ... (–¶–∏–∫–ª –ø–æ items_to_tag –æ—Å—Ç–∞–µ—Ç—Å—è –ø—Ä–µ–∂–Ω–∏–º: tags = generate_search_tags(description) —Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç lower())
    for p in items_to_tag:
        pid = p.get("id")
        desc = p.get("description", "")
        
        # 1. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–≥–æ–≤
        tags = generate_search_tags(desc) 
        
        if not tags:
            logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç %s ‚Äî –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–≥–∏.", pid)
            time.sleep(pause_between)
            continue
            
        # 2. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤ Supabase
        try:
            upd = supabase.table("products").update({"search_tags": tags}).eq("id", pid).execute()
            logger.info("–£—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω search_tags –¥–ª—è ID=%s: %s", pid, tags)
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–µ–≥–∞ –¥–ª—è ID=%s: %s", pid, e)# ... (–∫–æ–¥ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
        time.sleep(pause_between)
    
    # ====================================================
    # 2. –≠–ú–ë–ï–î–î–ò–ù–ì: –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –±–µ–∑ embedding –ò–õ–ò –≤—Å–µ —Ç–æ–≤–∞—Ä—ã (–µ—Å–ª–∏ --force)
    # ====================================================
    logger.info("--- –®–ê–ì 2: –†–ê–°–ß–ï–¢ –≠–ú–ë–ï–î–î–ò–ù–ì–û–í (embedding) ---")
    
    query = supabase.table("products").select("id,name,description,price,images,search_tags,pv,embedding")
    
    if not force_regenerate:
        # –û–±—ã—á–Ω—ã–π Backfill: –∏—â–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ–≥–æ –Ω–µ—Ç –≤–µ–∫—Ç–æ—Ä–∞
        query = query.is_("embedding", None)
        logger.info("–ó–∞–ø—É—â–µ–Ω —Ä–µ–∂–∏–º BACKFILL: –∏—â–µ–º —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã –±–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞.")
    else: 
        # –ü–æ–ª–Ω–∞—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è: –≤—ã–±–∏—Ä–∞–µ–º –≤—Å–µ
        logger.warning("–ó–∞–ø—É—â–µ–Ω —Ä–µ–∂–∏–º –ü–û–õ–ù–û–ô –†–ï–ì–ï–ù–ï–†–ê–¶–ò–ò (force=True). –ë—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã –í–°–ï —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.")
    
    # –ó–ê–ü–†–û–°
    res = query.limit(batch_size).execute()
    items_to_embed = res.data 
    logger.info("–ù–∞–π–¥–µ–Ω–æ %d –ø—Ä–æ–¥—É–∫—Ç–æ–≤, —Ç—Ä–µ–±—É—é—â–∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞", len(items_to_embed))
    
    for p in items_to_embed:
        pid = p.get("id")
        tags = p.get("search_tags", "")
        
        if not tags and not p.get("description"):
            logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç %s ‚Äî –Ω–µ—Ç –Ω–∏ –æ–ø–∏—Å–∞–Ω–∏—è, –Ω–∏ —Ç–µ–≥–æ–≤", pid)
            continue
        
        try:
            # üí° –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞ (—Å .lower())
            combined_text = get_product_text_for_embedding(p)
            
            # embed_text —Ç–∞–∫–∂–µ –¥–µ–ª–∞–µ—Ç .lower() (–¥–≤–æ–π–Ω–∞—è –∑–∞—â–∏—Ç–∞)
            vec = embed_text(combined_text) 
            
            if not vec:
                logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–¥—É–∫—Ç %s ‚Äî –ø—É—Å—Ç–æ–π –≤–µ–∫—Ç–æ—Ä", pid)
                continue
            
            logger.info("ID=%s, vector length=%d", pid, len(vec))
            upd = supabase.table("products").update({"embedding": vec}).eq("id", pid).execute()
            # ... (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫)
            
        except Exception as e:
            logger.exception("–û—à–∏–±–∫–∞ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∞ %s: %s", pid, e)
        finally:
            time.sleep(pause_between)
            
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--batch", type=int, default=100, help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è backfill")
    parser.add_argument("--pause", type=float, default=0.1, help="–ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å)")
    # üí° –ù–û–í–´–ô –ê–†–ì–£–ú–ï–ù–¢
    parser.add_argument("--force", action='store_true', help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –í–°–ï —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.") 
    args = parser.parse_args()
    
    backfill_product_embeddings(
        batch_size=args.batch, 
        pause_between=args.pause,
        force_regenerate=args.force # –ü–µ—Ä–µ–¥–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç
    )